{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Установка PySpark\n",
        "!pip install pyspark\n"
      ],
      "metadata": {
        "id": "pgs6emyiK-tX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02b45de7-d74d-4e6f-fdbf-55a4b9413417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Задание 1: Бинарная классификация**"
      ],
      "metadata": {
        "id": "-ozV9FUXLE4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем необходимые библиотеки"
      ],
      "metadata": {
        "id": "WQukSF6nZ9Xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "0HPnvLw6aEUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запускаем SparkSession"
      ],
      "metadata": {
        "id": "KXPl1-CnafMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Binary Classification\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "6ULqEb2pZzcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сгенерируем данные"
      ],
      "metadata": {
        "id": "DvTjejQ6atOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame({\n",
        "    'feature1': [0.1, 0.2, 0.4, 0.6, 0.8, 0.9, 0.3, 0.5, 0.7, 0.85],\n",
        "    'feature2': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
        "    'label': [0, 0, 0, 1, 1, 1, 0, 1, 1, 1]\n",
        "})\n",
        "\n",
        "df = spark.createDataFrame(data)"
      ],
      "metadata": {
        "id": "VI1fp5FbaxQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проведем векторизацию"
      ],
      "metadata": {
        "id": "VtASbcTIbD5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols=[\"feature1\", \"feature2\"], outputCol=\"features\")\n",
        "data_transformed = assembler.transform(df)"
      ],
      "metadata": {
        "id": "nbRf_fgKaxL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разделим данные на тренировочный и тестовый наборы"
      ],
      "metadata": {
        "id": "NH-09QYobJ2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = data_transformed.randomSplit([0.7, 0.3])"
      ],
      "metadata": {
        "id": "BWn042bcaxHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проведем обучение модели"
      ],
      "metadata": {
        "id": "IDop4FXJbY_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
        "model = lr.fit(train_data)"
      ],
      "metadata": {
        "id": "6uWJPZEoasTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проводим прогнозирование и оценку модели"
      ],
      "metadata": {
        "id": "OqMcLEIrbe1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test_data)\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\")\n",
        "accuracy = evaluator.evaluate(predictions)"
      ],
      "metadata": {
        "id": "gp_s7znvbhB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраняем метрики в файл"
      ],
      "metadata": {
        "id": "qrbtXn2ccQY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"binary_classification_metrics.txt\", \"w\") as f:\n",
        "    f.write(f\"Accuracy: {accuracy}\\n\")"
      ],
      "metadata": {
        "id": "8ogGCKyybg-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Binary Classification Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jyo2YXT-cVXP",
        "outputId": "e7b0f146-bc53-4891-d698-9224ab3a8038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary Classification Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "vGzD4zrIovYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Задание 2: Кластеризация (KMeans)**"
      ],
      "metadata": {
        "id": "SxXJKrijceBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "IJieX5S3cwCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"KMeans Example\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "aGNeePQ_dnOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сгенерируем подходящие исходные данные для проведения обучения"
      ],
      "metadata": {
        "id": "5lXmS7nIcm0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "data = []\n",
        "num_points_per_cluster = 100\n",
        "num_clusters = 3\n",
        "\n",
        "for i in range(num_clusters):\n",
        "    # Генерируем центры кластеров\n",
        "    center_x = np.random.rand() * 10\n",
        "    center_y = np.random.rand() * 10\n",
        "    for _ in range(num_points_per_cluster):\n",
        "        # Генерируем точки вокруг центра с небольшим шумом\n",
        "        point_x = center_x + np.random.randn() * 0.5\n",
        "        point_y = center_y + np.random.randn() * 0.5\n",
        "        data.append(Row(x=point_x, y=point_y))\n"
      ],
      "metadata": {
        "id": "8nBX3FJWZzT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем DataFrame"
      ],
      "metadata": {
        "id": "78yZnNoBc2_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  df = spark.createDataFrame(data)"
      ],
      "metadata": {
        "id": "WJM6_BS1d3Rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проведем подготовку данных"
      ],
      "metadata": {
        "id": "xTAF9SAEuYak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols=[\"x\", \"y\"], outputCol=\"features\")\n",
        "data_transformed = assembler.transform(df)"
      ],
      "metadata": {
        "id": "zvAlWsA9uPjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проведем обучение модели"
      ],
      "metadata": {
        "id": "FXkmnS39c9nM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(k=num_clusters, seed=42)\n",
        "model = kmeans.fit(data_transformed)"
      ],
      "metadata": {
        "id": "S57WZl1bqxJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получаем и выводим центры кластеров"
      ],
      "metadata": {
        "id": "r4JL41QgeYRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "centers = model.clusterCenters()\n",
        "for i, center in enumerate(centers):\n",
        "    print(f\"Center of cluster {i}: {center}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDb_4GjTuioC",
        "outputId": "355bead9-5c4c-42e7-b0f4-cedb3b7736dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Center of cluster 0: [7.0170251  7.01640171]\n",
            "Center of cluster 1: [7.67892194 9.38511125]\n",
            "Center of cluster 2: [3.68692443 9.52764947]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраняем в файл полученные центры кластеров"
      ],
      "metadata": {
        "id": "qGZuswtaeqTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"cluster_centers.txt\", \"w\") as f:\n",
        "    for i, center in enumerate(centers):\n",
        "        f.write(f\"Center of cluster {i}: {center}\\n\")"
      ],
      "metadata": {
        "id": "40-xxMdtetq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "Q_2f2f4eeWIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Задание 3. Регрессия (LinearRegression)**"
      ],
      "metadata": {
        "id": "MJEK0-6Ae6uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "xbRosc_5e3o1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Linear Regression Example\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "-LPxx_JNe3kc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сгенерируем подходящие исходные данные для проведения обучения"
      ],
      "metadata": {
        "id": "jaBSc9M7fj3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "num_points = 1000\n",
        "x = (np.random.rand(num_points) * 10).tolist()  # Признак в виде списка\n",
        "y = (2 * np.array(x) + 3 + np.random.randn(num_points) * 2).tolist()  #Создаем зависимую переменную с некоторым шумом"
      ],
      "metadata": {
        "id": "7PuezE-2e3a9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем DataFrame"
      ],
      "metadata": {
        "id": "ANZR0Ib9f7TW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(float(xi), float(yi)) for xi, yi in zip(x, y)]\n",
        "df = spark.createDataFrame(data, [\"x\", \"y\"])"
      ],
      "metadata": {
        "id": "UnjpCzDnferS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовим данные для обучения"
      ],
      "metadata": {
        "id": "vC-VEVGXgzO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols=[\"x\"], outputCol=\"features\")\n",
        "data_transformed = assembler.transform(df)"
      ],
      "metadata": {
        "id": "mM2Djvnjfem6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проведем обучение линейной регрессии"
      ],
      "metadata": {
        "id": "G3Y7MoCAg4q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"y\")\n",
        "lr_model = lr.fit(data_transformed)"
      ],
      "metadata": {
        "id": "YOpe3EHEgdpL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проведем прогнозирование и расчет метрик"
      ],
      "metadata": {
        "id": "YovbZIOhg_kX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = lr_model.transform(data_transformed)\n",
        "training_summary = lr_model.summary\n",
        "r2 = training_summary.r2\n",
        "rmse = training_summary.rootMeanSquaredError"
      ],
      "metadata": {
        "id": "rVRUpDzDg_TX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим значения метрик"
      ],
      "metadata": {
        "id": "rZkXmSfKhKSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"R2: {r2}\")\n",
        "print(f\"RMSE: {rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHQIoHagg_GE",
        "outputId": "b300f99e-e823-4250-9a37-8d7feae31c9b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2: 0.8944721603366936\n",
            "RMSE: 1.9748092381589237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраним полученные значения метрик в файл."
      ],
      "metadata": {
        "id": "J6C0dwx2hQqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"regression_metrics.txt\", \"w\") as f:\n",
        "    f.write(f\"R2: {r2}\\n\")\n",
        "    f.write(f\"RMSE: {rmse}\\n\")"
      ],
      "metadata": {
        "id": "Umi1c8A5g_BH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сгенерируем данные для кастеризации"
      ],
      "metadata": {
        "id": "5MNL5mt4jiR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_clusters = 3\n",
        "cluster_data = []\n",
        "for i in range(num_clusters):\n",
        "    center_x = np.random.rand() * 10\n",
        "    center_y = np.random.rand() * 10\n",
        "    for _ in range(100):\n",
        "        point_x = center_x + np.random.randn() * 0.5\n",
        "        point_y = center_y + np.random.randn() * 0.5\n",
        "        cluster_data.append((float(point_x), float(point_y)))"
      ],
      "metadata": {
        "id": "-1mbIHNEjhJl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим для кластеризации DataFrame"
      ],
      "metadata": {
        "id": "eikd2mX4jt8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_df = spark.createDataFrame(cluster_data, [\"x\", \"y\"])"
      ],
      "metadata": {
        "id": "2i5QYeINjqTu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подгготовим данные и проведем кластеризацию с помощью KMeans"
      ],
      "metadata": {
        "id": "Ke2-Wvqqj565"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols=[\"x\", \"y\"], outputCol=\"features\")\n",
        "cluster_data_transformed = assembler.transform(cluster_df)\n",
        "kmeans = KMeans(k=num_clusters, seed=42)\n",
        "kmeans_model = kmeans.fit(cluster_data_transformed)"
      ],
      "metadata": {
        "id": "UOw7Hpb2jp--"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получим, выведем и сохраним центры кластеров"
      ],
      "metadata": {
        "id": "jBRW6ykEkJm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "centers = kmeans_model.clusterCenters()\n",
        "\n",
        "print(\"Cluster Centers:\")\n",
        "for i, center in enumerate(centers):\n",
        "    print(f\"Center of cluster {i}: {center}\")\n",
        "\n",
        "with open(\"cluster_centers.txt\", \"w\") as f:\n",
        "    for i, center in enumerate(centers):\n",
        "        f.write(f\"Center of cluster {i}: {center}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPKcXwozkD6S",
        "outputId": "1ea2764a-5179-4a0d-e4a6-de9fcf9c4d55"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Centers:\n",
            "Center of cluster 0: [2.95188248 3.60068657]\n",
            "Center of cluster 1: [9.66904691 3.33060381]\n",
            "Center of cluster 2: [8.02470699 4.66428446]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "4ySn9xbFgdk6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Задание 4. Word2vec**"
      ],
      "metadata": {
        "id": "N8bOgvsrkqEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Word2Vec"
      ],
      "metadata": {
        "id": "WQboHDp0hfgF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Word2Vec Example\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "eYKrLgTwhfXk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"Белеет парус одинокий в тумане моря голубом!\",\n",
        "    \"Что ищет он в стране далекой?\",\n",
        "    \"Что кинул он в краю родном?\",\n",
        "    \"Играют волны — ветер свищет, и мачта гнется и скрипит…\",\n",
        "    \"Увы, он счастия не ищет и не от счастия бежит!\",\n",
        "    \"Под ним струя светлей лазури, над ним луч солнца золотой…\",\n",
        "    \"А он, мятежный, просит бури, Как будто в бурях есть покой!\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "xHgWYrY0l525"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразуем предложения в DataFrame"
      ],
      "metadata": {
        "id": "ZtBk5vGLm-Vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(sentence.split(\" \"),) for sentence in sentences]\n",
        "df = spark.createDataFrame(data, [\"text\"])"
      ],
      "metadata": {
        "id": "ZQyQ5tFRgdbv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовим данных для Word2Vec, представив каждое предложение в виде списка слов\n"
      ],
      "metadata": {
        "id": "qW918Rr2nB1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(truncate=False)"
      ],
      "metadata": {
        "id": "9tVOuLT3l5ga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "956e6f1b-8662-4ad1-f8d6-a183c0a1c9c8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------+\n",
            "|text                                                                  |\n",
            "+----------------------------------------------------------------------+\n",
            "|[Белеет, парус, одинокий, в, тумане, моря, голубом!]                  |\n",
            "|[Что, ищет, он, в, стране, далекой?]                                  |\n",
            "|[Что, кинул, он, в, краю, родном?]                                    |\n",
            "|[Играют, волны, —, ветер, свищет,, и, мачта, гнется, и, скрипит…]     |\n",
            "|[Увы,, он, счастия, не, ищет, и, не, от, счастия, бежит!]             |\n",
            "|[Под, ним, струя, светлей, лазури,, над, ним, луч, солнца, золотой…]  |\n",
            "|[А, он,, мятежный,, просит, бури,, Как, будто, в, бурях, есть, покой!]|\n",
            "+----------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучаем модели Word2Vec"
      ],
      "metadata": {
        "id": "a2D4Cl83nVWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol=\"text\", outputCol=\"result\")\n",
        "model = word2Vec.fit(df)"
      ],
      "metadata": {
        "id": "W6-TrWdcl5cc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразуем слова в векторы"
      ],
      "metadata": {
        "id": "g2aV_xPZnnB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transform(df)"
      ],
      "metadata": {
        "id": "sXhxEvOZl5Y6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим результат"
      ],
      "metadata": {
        "id": "T1TlC2zqnvsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UricV2aAnmQJ",
        "outputId": "c7144c7d-f742-4745-c02a-52b6838bac85"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------+-------------------------------------------------------------------+\n",
            "|text                                                                  |result                                                             |\n",
            "+----------------------------------------------------------------------+-------------------------------------------------------------------+\n",
            "|[Белеет, парус, одинокий, в, тумане, моря, голубом!]                  |[0.02615223093224423,0.04188473762146064,0.012471183203160763]     |\n",
            "|[Что, ищет, он, в, стране, далекой?]                                  |[0.0037275906652212143,-0.04420801729429513,-0.014807784464210272] |\n",
            "|[Что, кинул, он, в, краю, родном?]                                    |[-0.010152634854118029,-0.026048003191438813,0.002213459461927414] |\n",
            "|[Играют, волны, —, ветер, свищет,, и, мачта, гнется, и, скрипит…]     |[2.8135075699537994E-4,-0.0059743637684732676,0.008829496800899506]|\n",
            "|[Увы,, он, счастия, не, ищет, и, не, от, счастия, бежит!]             |[0.028947785869240763,0.04863029059488327,-0.044844315946102144]   |\n",
            "|[Под, ним, струя, светлей, лазури,, над, ним, луч, солнца, золотой…]  |[-0.06689009815454483,-0.019596422743052247,-0.07505401000380517]  |\n",
            "|[А, он,, мятежный,, просит, бури,, Как, будто, в, бурях, есть, покой!]|[-0.02671109089119868,-0.027367914476516573,-0.0020449940453876147]|\n",
            "+----------------------------------------------------------------------+-------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраним векторы в файл"
      ],
      "metadata": {
        "id": "XyJimOK4n07y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = result.select(\"text\", \"result\").rdd.map(lambda row: (row[0], row[1].toArray().tolist()))\n",
        "with open(\"word_vectors.txt\", \"w\", encoding='utf-8') as f:\n",
        "    for sentence, vector in vectors.collect():\n",
        "        f.write(f\"Sentence: {sentence}, Vectors: {vector}\\n\")\n"
      ],
      "metadata": {
        "id": "4uLgCXCsnmMo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "9U-95w7PnmIw"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}